{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib as mpl\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ISO3_Code', 'Country_Name', 'M49_Code', 'Life_Expectancy_2016',\n",
      "       'Life_Expectancy_2017', 'Life_Expectancy_2018', 'Life_Expectancy_2019',\n",
      "       'Life_Expectancy_2020', 'Life_Expectancy_Avg',\n",
      "       'Mean_Years_Of_Schooling_2016', 'Mean_Years_Of_Schooling_2017',\n",
      "       'Mean_Years_Of_Schooling_2018', 'Mean_Years_Of_Schooling_2019',\n",
      "       'Mean_Years_Of_Schooling_2020', 'Mean_Years_of_Schooling_Avg'],\n",
      "      dtype='object')\n",
      "Index(['M49_Code', 'Country_Name', 'ISO3 Code', 'CPI_Food_2016',\n",
      "       'CPI_Food_2017', 'CPI_Food_2018', 'CPI_Food_2019', 'CPI_Food_2020',\n",
      "       'CPI_Food_Avg'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'M49_Code', 'Country_Name',\n",
      "       'Prevalence_of_undernourishment_2016',\n",
      "       'Prevalence_of_undernourishment_2017',\n",
      "       'Prevalence_of_undernourishment_2018',\n",
      "       'Prevalence_of_undernourishment_2019',\n",
      "       'Prevalence_of_undernourishment_2020'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Merge all csv files\n",
    "files = [\".\\datasets\\Processed\\SocioFactors_Processed.csv\", \".\\datasets\\Processed\\CPI_Food_Processed.csv\", \".\\datasets\\Processed\\Prevalence_of_Undernourishment_Processed.csv\"]\n",
    "try:    \n",
    "    dfs = [pd.read_csv(file, encoding='utf8') for file in files]\n",
    "except:\n",
    "    dfs = [pd.read_csv(file, encoding='ISO-8859-1') for file in files]\n",
    "print(dfs[0].columns)\n",
    "print(dfs[1].columns)\n",
    "print(dfs[2].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['M49_Code', 'CPI_Food_2016', 'CPI_Food_2017', 'CPI_Food_2018',\n",
      "       'CPI_Food_2019', 'CPI_Food_2020', 'CPI_Food_Avg'],\n",
      "      dtype='object')\n",
      "Index(['M49_Code', 'Prevalence_of_undernourishment_2016',\n",
      "       'Prevalence_of_undernourishment_2017',\n",
      "       'Prevalence_of_undernourishment_2018',\n",
      "       'Prevalence_of_undernourishment_2019',\n",
      "       'Prevalence_of_undernourishment_2020'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "dfs[1].drop(columns=[\"Country_Name\", \"ISO3 Code\"], inplace=True)\n",
    "dfs[2].rename(columns={\"Area Code (M49)\": \"M49_Code\"}, inplace=True)\n",
    "dfs[2].drop(columns=[\"Unnamed: 0\", \"Country_Name\"], inplace=True)\n",
    "print(dfs[1].columns)\n",
    "print(dfs[2].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISO3_Code</th>\n",
       "      <th>Country_Name</th>\n",
       "      <th>M49_Code</th>\n",
       "      <th>Life_Expectancy_2016</th>\n",
       "      <th>Life_Expectancy_2017</th>\n",
       "      <th>Life_Expectancy_2018</th>\n",
       "      <th>Life_Expectancy_2019</th>\n",
       "      <th>Life_Expectancy_2020</th>\n",
       "      <th>Life_Expectancy_Avg</th>\n",
       "      <th>Mean_Years_Of_Schooling_2016</th>\n",
       "      <th>...</th>\n",
       "      <th>CPI_Food_2017</th>\n",
       "      <th>CPI_Food_2018</th>\n",
       "      <th>CPI_Food_2019</th>\n",
       "      <th>CPI_Food_2020</th>\n",
       "      <th>CPI_Food_Avg</th>\n",
       "      <th>Prevalence_of_undernourishment_2016</th>\n",
       "      <th>Prevalence_of_undernourishment_2017</th>\n",
       "      <th>Prevalence_of_undernourishment_2018</th>\n",
       "      <th>Prevalence_of_undernourishment_2019</th>\n",
       "      <th>Prevalence_of_undernourishment_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.1361</td>\n",
       "      <td>63.0160</td>\n",
       "      <td>63.0810</td>\n",
       "      <td>63.5645</td>\n",
       "      <td>62.5751</td>\n",
       "      <td>63.07454</td>\n",
       "      <td>2.463660</td>\n",
       "      <td>...</td>\n",
       "      <td>113.832502</td>\n",
       "      <td>113.490296</td>\n",
       "      <td>119.067918</td>\n",
       "      <td>128.002089</td>\n",
       "      <td>116.661927</td>\n",
       "      <td>22.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.9</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>24.0</td>\n",
       "      <td>61.0923</td>\n",
       "      <td>61.6798</td>\n",
       "      <td>62.1438</td>\n",
       "      <td>62.4484</td>\n",
       "      <td>62.2612</td>\n",
       "      <td>61.92510</td>\n",
       "      <td>5.417391</td>\n",
       "      <td>...</td>\n",
       "      <td>183.757815</td>\n",
       "      <td>211.993524</td>\n",
       "      <td>252.263872</td>\n",
       "      <td>330.372845</td>\n",
       "      <td>226.504966</td>\n",
       "      <td>15.4</td>\n",
       "      <td>15.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>8.0</td>\n",
       "      <td>78.8602</td>\n",
       "      <td>79.0473</td>\n",
       "      <td>79.1838</td>\n",
       "      <td>79.2825</td>\n",
       "      <td>76.9893</td>\n",
       "      <td>78.67262</td>\n",
       "      <td>10.727528</td>\n",
       "      <td>...</td>\n",
       "      <td>107.497139</td>\n",
       "      <td>110.638289</td>\n",
       "      <td>113.430423</td>\n",
       "      <td>116.338895</td>\n",
       "      <td>110.498683</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ARE</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>784.0</td>\n",
       "      <td>79.3347</td>\n",
       "      <td>79.5036</td>\n",
       "      <td>79.6274</td>\n",
       "      <td>79.7262</td>\n",
       "      <td>78.9457</td>\n",
       "      <td>79.42752</td>\n",
       "      <td>10.842620</td>\n",
       "      <td>...</td>\n",
       "      <td>104.268174</td>\n",
       "      <td>105.564297</td>\n",
       "      <td>104.435251</td>\n",
       "      <td>108.084044</td>\n",
       "      <td>104.669966</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>32.0</td>\n",
       "      <td>76.3077</td>\n",
       "      <td>76.8330</td>\n",
       "      <td>76.9994</td>\n",
       "      <td>77.2845</td>\n",
       "      <td>75.8921</td>\n",
       "      <td>76.66334</td>\n",
       "      <td>10.928190</td>\n",
       "      <td>...</td>\n",
       "      <td>143.476356</td>\n",
       "      <td>216.878531</td>\n",
       "      <td>340.091177</td>\n",
       "      <td>483.126590</td>\n",
       "      <td>260.555733</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>VNM</td>\n",
       "      <td>Viet Nam</td>\n",
       "      <td>704.0</td>\n",
       "      <td>73.9382</td>\n",
       "      <td>73.9632</td>\n",
       "      <td>73.9757</td>\n",
       "      <td>74.0929</td>\n",
       "      <td>75.3779</td>\n",
       "      <td>74.26958</td>\n",
       "      <td>8.122675</td>\n",
       "      <td>...</td>\n",
       "      <td>101.286235</td>\n",
       "      <td>106.442999</td>\n",
       "      <td>116.199618</td>\n",
       "      <td>119.316440</td>\n",
       "      <td>109.276986</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>VUT</td>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>548.0</td>\n",
       "      <td>69.6496</td>\n",
       "      <td>69.7095</td>\n",
       "      <td>69.7948</td>\n",
       "      <td>69.8769</td>\n",
       "      <td>70.2995</td>\n",
       "      <td>69.86606</td>\n",
       "      <td>6.680000</td>\n",
       "      <td>...</td>\n",
       "      <td>111.462978</td>\n",
       "      <td>114.940160</td>\n",
       "      <td>123.246759</td>\n",
       "      <td>140.246312</td>\n",
       "      <td>118.932479</td>\n",
       "      <td>11.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.4</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>WSM</td>\n",
       "      <td>Samoa</td>\n",
       "      <td>882.0</td>\n",
       "      <td>72.5397</td>\n",
       "      <td>72.5900</td>\n",
       "      <td>72.6358</td>\n",
       "      <td>72.1572</td>\n",
       "      <td>72.7677</td>\n",
       "      <td>72.53808</td>\n",
       "      <td>11.526498</td>\n",
       "      <td>...</td>\n",
       "      <td>110.697788</td>\n",
       "      <td>109.340413</td>\n",
       "      <td>114.669831</td>\n",
       "      <td>105.476923</td>\n",
       "      <td>109.139743</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>YEM</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>887.0</td>\n",
       "      <td>66.0641</td>\n",
       "      <td>65.9573</td>\n",
       "      <td>64.5751</td>\n",
       "      <td>65.0917</td>\n",
       "      <td>64.6501</td>\n",
       "      <td>65.26766</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>128.044919</td>\n",
       "      <td>134.901926</td>\n",
       "      <td>143.908187</td>\n",
       "      <td>152.999508</td>\n",
       "      <td>136.351526</td>\n",
       "      <td>46.1</td>\n",
       "      <td>46.6</td>\n",
       "      <td>44.7</td>\n",
       "      <td>42.8</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>ZAF</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>710.0</td>\n",
       "      <td>64.7469</td>\n",
       "      <td>65.4020</td>\n",
       "      <td>65.6743</td>\n",
       "      <td>66.1750</td>\n",
       "      <td>65.2522</td>\n",
       "      <td>65.45008</td>\n",
       "      <td>10.187880</td>\n",
       "      <td>...</td>\n",
       "      <td>120.791800</td>\n",
       "      <td>124.103200</td>\n",
       "      <td>128.998200</td>\n",
       "      <td>136.628700</td>\n",
       "      <td>125.283740</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ISO3_Code          Country_Name  M49_Code  Life_Expectancy_2016  \\\n",
       "0         AFG           Afghanistan       4.0               63.1361   \n",
       "1         AGO                Angola      24.0               61.0923   \n",
       "2         ALB               Albania       8.0               78.8602   \n",
       "3         ARE  United Arab Emirates     784.0               79.3347   \n",
       "4         ARG             Argentina      32.0               76.3077   \n",
       "..        ...                   ...       ...                   ...   \n",
       "147       VNM              Viet Nam     704.0               73.9382   \n",
       "148       VUT               Vanuatu     548.0               69.6496   \n",
       "149       WSM                 Samoa     882.0               72.5397   \n",
       "150       YEM                 Yemen     887.0               66.0641   \n",
       "151       ZAF          South Africa     710.0               64.7469   \n",
       "\n",
       "     Life_Expectancy_2017  Life_Expectancy_2018  Life_Expectancy_2019  \\\n",
       "0                 63.0160               63.0810               63.5645   \n",
       "1                 61.6798               62.1438               62.4484   \n",
       "2                 79.0473               79.1838               79.2825   \n",
       "3                 79.5036               79.6274               79.7262   \n",
       "4                 76.8330               76.9994               77.2845   \n",
       "..                    ...                   ...                   ...   \n",
       "147               73.9632               73.9757               74.0929   \n",
       "148               69.7095               69.7948               69.8769   \n",
       "149               72.5900               72.6358               72.1572   \n",
       "150               65.9573               64.5751               65.0917   \n",
       "151               65.4020               65.6743               66.1750   \n",
       "\n",
       "     Life_Expectancy_2020  Life_Expectancy_Avg  Mean_Years_Of_Schooling_2016  \\\n",
       "0                 62.5751             63.07454                      2.463660   \n",
       "1                 62.2612             61.92510                      5.417391   \n",
       "2                 76.9893             78.67262                     10.727528   \n",
       "3                 78.9457             79.42752                     10.842620   \n",
       "4                 75.8921             76.66334                     10.928190   \n",
       "..                    ...                  ...                           ...   \n",
       "147               75.3779             74.26958                      8.122675   \n",
       "148               70.2995             69.86606                      6.680000   \n",
       "149               72.7677             72.53808                     11.526498   \n",
       "150               64.6501             65.26766                      3.000000   \n",
       "151               65.2522             65.45008                     10.187880   \n",
       "\n",
       "     ...  CPI_Food_2017  CPI_Food_2018  CPI_Food_2019  CPI_Food_2020  \\\n",
       "0    ...     113.832502     113.490296     119.067918     128.002089   \n",
       "1    ...     183.757815     211.993524     252.263872     330.372845   \n",
       "2    ...     107.497139     110.638289     113.430423     116.338895   \n",
       "3    ...     104.268174     105.564297     104.435251     108.084044   \n",
       "4    ...     143.476356     216.878531     340.091177     483.126590   \n",
       "..   ...            ...            ...            ...            ...   \n",
       "147  ...     101.286235     106.442999     116.199618     119.316440   \n",
       "148  ...     111.462978     114.940160     123.246759     140.246312   \n",
       "149  ...     110.697788     109.340413     114.669831     105.476923   \n",
       "150  ...     128.044919     134.901926     143.908187     152.999508   \n",
       "151  ...     120.791800     124.103200     128.998200     136.628700   \n",
       "\n",
       "     CPI_Food_Avg  Prevalence_of_undernourishment_2016  \\\n",
       "0      116.661927                                 22.2   \n",
       "1      226.504966                                 15.4   \n",
       "2      110.498683                                  4.7   \n",
       "3      104.669966                                  6.3   \n",
       "4      260.555733                                  2.6   \n",
       "..            ...                                  ...   \n",
       "147    109.276986                                  7.8   \n",
       "148    118.932479                                 11.2   \n",
       "149    109.139743                                  4.7   \n",
       "150    136.351526                                 46.1   \n",
       "151    125.283740                                  5.4   \n",
       "\n",
       "     Prevalence_of_undernourishment_2017  Prevalence_of_undernourishment_2018  \\\n",
       "0                                   23.0                                 24.0   \n",
       "1                                   15.4                                 15.7   \n",
       "2                                    4.7                                  4.6   \n",
       "3                                    6.4                                  6.2   \n",
       "4                                    3.1                                  3.4   \n",
       "..                                   ...                                  ...   \n",
       "147                                  7.2                                  6.8   \n",
       "148                                 12.3                                 12.6   \n",
       "149                                  4.6                                  4.5   \n",
       "150                                 46.6                                 44.7   \n",
       "151                                  5.5                                  5.7   \n",
       "\n",
       "     Prevalence_of_undernourishment_2019  Prevalence_of_undernourishment_2020  \n",
       "0                                   26.9                                 29.8  \n",
       "1                                   17.9                                 20.8  \n",
       "2                                    4.3                                  3.9  \n",
       "3                                    6.0                                  5.6  \n",
       "4                                    3.5                                  3.7  \n",
       "..                                   ...                                  ...  \n",
       "147                                  6.2                                  5.7  \n",
       "148                                 12.4                                 11.9  \n",
       "149                                  4.4                                  4.4  \n",
       "150                                 42.8                                 41.4  \n",
       "151                                  6.3                                  6.9  \n",
       "\n",
       "[152 rows x 26 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfs[0]\n",
    "df = df.merge(dfs[1], on=\"M49_Code\", how=\"inner\")\n",
    "df = df.merge(dfs[2], on=\"M49_Code\", how=\"inner\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sean\\AppData\\Local\\Temp\\ipykernel_24724\\1916672156.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.fillna(df.mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ISO3_Code                              0\n",
       "Country_Name                           0\n",
       "M49_Code                               0\n",
       "Life_Expectancy_2016                   0\n",
       "Life_Expectancy_2017                   0\n",
       "Life_Expectancy_2018                   0\n",
       "Life_Expectancy_2019                   0\n",
       "Life_Expectancy_2020                   0\n",
       "Life_Expectancy_Avg                    0\n",
       "Mean_Years_Of_Schooling_2016           0\n",
       "Mean_Years_Of_Schooling_2017           0\n",
       "Mean_Years_Of_Schooling_2018           0\n",
       "Mean_Years_Of_Schooling_2019           0\n",
       "Mean_Years_Of_Schooling_2020           0\n",
       "Mean_Years_of_Schooling_Avg            0\n",
       "CPI_Food_2016                          0\n",
       "CPI_Food_2017                          0\n",
       "CPI_Food_2018                          0\n",
       "CPI_Food_2019                          0\n",
       "CPI_Food_2020                          0\n",
       "CPI_Food_Avg                           0\n",
       "Prevalence_of_undernourishment_2016    0\n",
       "Prevalence_of_undernourishment_2017    0\n",
       "Prevalence_of_undernourishment_2018    0\n",
       "Prevalence_of_undernourishment_2019    0\n",
       "Prevalence_of_undernourishment_2020    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace all null values by mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers i.e. 3std away from mean\n",
    "# Apply this function during trials\n",
    "# This ain't working!!!\n",
    "# def remove_outliers(df_tmp):\n",
    "#     df_features_tmp = df_tmp.iloc[:, :-1].copy()\n",
    "#     mean, std = df_features_tmp.mean(), df_features_tmp.std()\n",
    "#     lower, upper = mean - 3 * std, mean + 3 * std\n",
    "#     lower, upper = np.expand_dims(lower, axis=0), np.expand_dims(upper, axis=0)\n",
    "#     lower_indexes = df_features_tmp[df_features_tmp < lower].index\n",
    "#     upper_indexes = df_features_tmp[df_features_tmp > upper].index\n",
    "#     original_m = df_tmp.shape[0]\n",
    "#     print(\"Outliers:      \", lower_indexes.size + upper_indexes.size)\n",
    "#     return df_tmp.iloc[(~lower_indexes) & (~upper_indexes), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Native Functions for Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_z(df):\n",
    "    return (df - df.mean(axis=0))/df.std(axis=0)\n",
    "\n",
    "def get_features_targets(df, feature_names, target_names):\n",
    "    df_feature = df[feature_names]\n",
    "    df_target = df[target_names]\n",
    "    return df_feature, df_target\n",
    "\n",
    "def prepare_feature(df_feature):\n",
    "    const = np.full(shape=(df_feature.shape[0], 1), fill_value=1)\n",
    "    conv = np.array(df_feature)\n",
    "    return np.concatenate((const, conv), axis=1)\n",
    "\n",
    "def prepare_target(df_target):\n",
    "    return np.array(df_target)\n",
    "\n",
    "def predict(df_feature, beta):\n",
    "    arr_feature_norm = prepare_feature(normalize_z(df_feature))\n",
    "    return calc_linear(arr_feature_norm, beta)\n",
    "\n",
    "def calc_linear(X, beta):\n",
    "    return np.matmul(X, beta)\n",
    "\n",
    "def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n",
    "    if random_state != None:\n",
    "        np.random.seed(random_state)\n",
    "    indexes = df_feature.index\n",
    "    k = int(len(indexes) * test_size)\n",
    "    test_index = set(np.random.choice(a=indexes, size=k, replace=False))\n",
    "    train_index = set(indexes) - test_index\n",
    "\n",
    "    df_feature_train = df_feature.loc[train_index, :]\n",
    "    df_feature_test = df_feature.loc[test_index, :]\n",
    "    df_target_train = df_target.loc[train_index, :]\n",
    "    df_target_test = df_target.loc[test_index, :]\n",
    "    return df_feature_train, df_feature_test, df_target_train, df_target_test\n",
    "  \n",
    "def r2_score(y, ypred):\n",
    "    y_bar = (1/len(y))*(np.sum(y, axis=0))\n",
    "    SS_tot = np.sum((y - y_bar)**2, axis=0)\n",
    "    SS_res = np.sum((y - ypred)**2, axis=0)\n",
    "    return (1 - (SS_res/SS_tot))\n",
    "\n",
    "def mean_squared_error(target, pred):\n",
    "    return ( (1/len(target)) * (np.sum((target - pred)**2, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the df_features & df_target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 1\n",
    "Input: 16 variables (format: Var_Year) <br>\n",
    "Output: 1 variable (undernourishment in 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 22)\n",
      "(152, 19)\n"
     ]
    }
   ],
   "source": [
    "# Leave output column as prevalence of undernourishment in 2020\n",
    "df_proc = pd.concat([df.iloc[:, :-5], df.iloc[:, -1]], axis=1)\n",
    "print(df_proc.shape)\n",
    "# Remove all avg columns\n",
    "df_proc = df_proc.loc[:, ~df_proc.columns.str.contains('Avg')]\n",
    "print(df_proc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  62.55225654503404\n",
      "r2_score 0.369233871125778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove first 3 columns i.e. M49 Code etc\n",
    "df_features, df_label = df_proc.iloc[:, 3:-1], df_proc.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_label, test_size = 0.2, random_state=100)\n",
    "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"r2_score\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2\n",
    "Input: 4 variables (format: Var_Avg) <br>\n",
    "Output: 1 variable (undernourishment in 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 22)\n",
      "(152, 6)\n"
     ]
    }
   ],
   "source": [
    "# Leave output column as prevalence of undernourishment in 2020\n",
    "df_proc = pd.concat([df.iloc[:, :-5], df.iloc[:, -1]], axis=1)\n",
    "print(df_proc.shape)\n",
    "# Remove all columns but avg columns\n",
    "df_proc = df_proc.loc[:, ~df_proc.columns.str.contains('_20')]\n",
    "print(df_proc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1.5546996715278216e+16\n",
      "r2_score -2310760156857.6235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove first 3 columns i.e. M49 Code etc\n",
    "df_features, df_label = df_proc.iloc[:, 3:-1], df_proc.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_label, test_size = 0.2, random_state=100)\n",
    "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"r2_score\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 3\n",
    "Input: 20 variables (format: Var_Year & Var_Avg) <br>\n",
    "Output: 1 variable (undernourishment in 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 22)\n"
     ]
    }
   ],
   "source": [
    "# Leave output column as prevalence of undernourishment in 2020\n",
    "df_proc = pd.concat([df.iloc[:, :-5], df.iloc[:, -1]], axis=1)\n",
    "print(df_proc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  70.77400317450494\n",
      "r2_score 0.28632720107907195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove first 3 columns i.e. M49 Code etc\n",
    "df_features, df_label = df_proc.iloc[:, 3:-1], df_proc.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, df_label, test_size = 0.2, random_state=100)\n",
    "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"r2_score\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 4\n",
    "Input: 4 variables (format: Var_20xx) <br>\n",
    "Output: 1 variable (undernourishment in 20xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year:           2016\n",
      "MSE:            46.23001402704181\n",
      "MAE (%):        1.079015332699846\n",
      "r2_score:       0.4217877347331368\n",
      "Adj r2_score:   0.3575419274812631\n",
      "Year:           2017\n",
      "MSE:            45.58171141097745\n",
      "MAE (%):        1.0435722072607145\n",
      "r2_score:       0.4295401674139352\n",
      "Adj r2_score:   0.36615574157103914\n",
      "Year:           2018\n",
      "MSE:            49.492448151795294\n",
      "MAE (%):        1.1112265233463114\n",
      "r2_score:       0.3856831308498423\n",
      "Adj r2_score:   0.31742570094426925\n",
      "Year:           2019\n",
      "MSE:            50.21145343968363\n",
      "MAE (%):        1.079646164023842\n",
      "r2_score:       0.4258409977311701\n",
      "Adj r2_score:   0.3620455530346335\n",
      "Year:           2020\n",
      "MSE:            48.92328239596575\n",
      "MAE (%):        1.1168344356564852\n",
      "r2_score:       0.5066660876333555\n",
      "Adj r2_score:   0.4518512084815062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove all columns but 20xx\n",
    "years = [2016, 2017, 2018, 2019, 2020]\n",
    "for i, year in enumerate(years):\n",
    "    df_proc = df.loc[:, df.columns.str.contains(str(year))]\n",
    "    print(\"Year:          \", year)\n",
    "\n",
    "    df_features, df_label = df_proc.iloc[:, :-1], df_proc.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, df_label, test_size = 0.2, random_state=100)\n",
    "    model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"MSE:           \", mean_squared_error(y_test, y_pred))\n",
    "    print(\"MAE (%):       \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print(\"r2_score:      \", r2_score(y_test, y_pred))\n",
    "    r2, n, p = r2_score(y_test, y_pred), y_test.shape[0], X_test.shape[1]\n",
    "    adj = 1 - (1 - r2) * (n-1) / (n-p-1)\n",
    "    print(\"Adj r2_score:  \", adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 5\n",
    "Input: 3 variables (format: Var_2020) <br>\n",
    "Output: 1 variable (undernourishment in 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped col:    Life_Expectancy_2020\n",
      "Train/test:     121/31\n",
      "MSE:            41.80069508198486\n",
      "MAE (%):        0.6386316714617071\n",
      "r2_score:       0.5784890253777979\n",
      "Adj r2_score:   0.5483810986190691\n",
      "Dropped col:    Mean_Years_Of_Schooling_2020\n",
      "Train/test:     121/31\n",
      "MSE:            60.373953616948384\n",
      "MAE (%):        1.3205061091484422\n",
      "r2_score:       0.39119950084650235\n",
      "Adj r2_score:   0.34771375090696677\n",
      "Dropped col:    CPI_Food_2020\n",
      "Train/test:     121/31\n",
      "MSE:            50.43110825482137\n",
      "MAE (%):        1.1448848699078686\n",
      "r2_score:       0.4914614326370632\n",
      "Adj r2_score:   0.45513724925399635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove all columns but 2020\n",
    "df_proc = df.loc[:, df.columns.str.contains(\"2020\")]\n",
    "columns = df_proc.columns[:-1]\n",
    "for i, column in enumerate(columns):\n",
    "    df_tmp = df_proc.loc[:, ~df_proc.columns.str.contains(column)]\n",
    "    print(\"Dropped col:   \", column)\n",
    "\n",
    "    # Remove outliers\n",
    "    # NOt working yet\n",
    "    # df_tmp = remove_outliers(df_tmp)\n",
    "\n",
    "    df_features, df_label = df_tmp.iloc[:, :-1], df_tmp.iloc[:, -1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, df_label, test_size = 0.2, random_state=100)\n",
    "    print(\"Train/test:    \", \"%d/%d\" % (X_train.shape[0], X_test.shape[0]))\n",
    "    model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"MSE:           \", mean_squared_error(y_test, y_pred))\n",
    "    print(\"MAE (%):       \", mean_absolute_percentage_error(y_test, y_pred))\n",
    "    print(\"r2_score:      \", r2_score(y_test, y_pred))\n",
    "    r2, n, p = r2_score(y_test, y_pred), y_test.shape[0], X_test.shape[1]\n",
    "    adj = 1 - (1 - r2) * (n-1) / (n-p-1)\n",
    "    print(\"Adj r2_score:  \", adj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('viz_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e714549f14d03f6249c54208929618ad61ce019036de2975eef5f164089b37f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
